import math

import numpy as np
import torch
from sklearn.metrics import average_precision_score, roc_auc_score

def eval_edge_prediction(model, negative_edge_sampler, data, n_neighbors, batch_size=200):
  assert negative_edge_sampler.seed is not None
  negative_edge_sampler.reset_random_state()

  val_ap, val_auc = [], []
  with torch.no_grad():
    model = model.eval()
    TEST_BATCH_SIZE = batch_size
    num_test_instance = len(data.sources)
    num_test_batch = math.ceil(num_test_instance / TEST_BATCH_SIZE)

    for k in range(num_test_batch):
      s_idx = k * TEST_BATCH_SIZE
      e_idx = min(num_test_instance, s_idx + TEST_BATCH_SIZE)
      sources_batch = data.sources[s_idx:e_idx]
      destinations_batch = data.destinations[s_idx:e_idx]
      timestamps_batch = data.timestamps[s_idx:e_idx]
      edge_idxs_batch = data.edge_idxs[s_idx: e_idx]

      size = len(sources_batch)
      _, negative_samples = negative_edge_sampler.sample(size)

      pos_prob, neg_prob = model.compute_edge_probabilities(sources_batch, destinations_batch,
                                                            negative_samples, timestamps_batch,
                                                            edge_idxs_batch, n_neighbors)

      pred_score = np.concatenate([(pos_prob).cpu().numpy(), (neg_prob).cpu().numpy()])
      true_label = np.concatenate([np.ones(size), np.zeros(size)])

      val_ap.append(average_precision_score(true_label, pred_score))
      val_auc.append(roc_auc_score(true_label, pred_score))

  return np.mean(val_ap), np.mean(val_auc)


def hr_ndcg(testdata, predictions, k=None):
    """
    Function to evaluate the performance of a recommender system using HR and NDCG metrics.

    Parameters:
    - testdata: Test set, with each record formatted as userid, itemid, rating (0 or 1)
    - predictions: Recommendation list generated by the recommender system, formatted as userid, itemid, rating (0 or 1)
    - k: The number of top items to consider

    Returns:
    - hr_score: Hit Rate
    - ndcg_score: NDCG score
    """
    sorted_predictions = predictions[np.argsort(predictions[:, 2],kind='mergesort')[::-1]]

    recommendations = {}
    for user_id, item_id, _ in sorted_predictions:
        if user_id not in recommendations:
            recommendations[user_id] = []
        recommendations[user_id].append(item_id)
    # print("recommendations.....\n:",recommendations)
    hr_sum = 0
    ndcg_sum = 0
    total_users = len(set(testdata[:, 0]))

    for user_id in set(testdata[:, 0]):
        true_items = set(testdata[(testdata[:, 0] == user_id) & (testdata[:, 2] == 1)][:, 1])
        # print("true_items:",true_items)
        if user_id in recommendations:
            predicted_ranking = recommendations[user_id]
            hr_sum += hit_rate(predicted_ranking, true_items,k)
            ndcg_sum += ndcg(predicted_ranking, true_items, k)

    hr_score = hr_sum / total_users
    ndcg_score = ndcg_sum / total_users

    return hr_score, ndcg_score


def eval_edge_prediction_ndcg(model, negative_edge_sampler, data, n_neighbors, batch_size=100):
    assert negative_edge_sampler.seed is not None
    negative_edge_sampler.reset_random_state()
    torch.cuda.empty_cache()
    hr_ndcg_total_dict = {}
    with torch.no_grad():
        model = model.eval()
        TEST_BATCH_SIZE = batch_size
        num_test_instance = len(data.sources)
        num_test_batch = math.ceil(num_test_instance / TEST_BATCH_SIZE)
        hr_ndcg_ave_dict = {}
        for i in range(1, 11):
            key = str(i)
            hr_ndcg_ave_dict[key] = [0, 0]
            hr_ndcg_total_dict[key] = [0, 0]
        for k in range(num_test_batch):
            s_idx = k * TEST_BATCH_SIZE
            num_sample = TEST_BATCH_SIZE + s_idx
            e_idx = min(num_test_instance, s_idx + TEST_BATCH_SIZE)
            sources_batch = data.sources[s_idx:e_idx]
            destinations_batch = data.destinations[s_idx:e_idx]
            timestamps_batch = data.timestamps[s_idx:e_idx]
            edge_idxs_batch = data.edge_idxs[s_idx:e_idx]
            r_batch =data.labels[s_idx:e_idx]
            size = len(sources_batch)
            _, negative_samples = negative_edge_sampler.sample(size)

            pos_prob, neg_prob = model.compute_edge_probabilities(sources_batch, destinations_batch,
                                                                  negative_samples, timestamps_batch,
                                                                  edge_idxs_batch, n_neighbors)
            predictions = pos_prob.cpu().numpy().squeeze()
            # predictions = np.where(predictions >= 0.5, 1, 0)
            all_predictions = np.column_stack((sources_batch, destinations_batch, predictions))
            all_ground_truth = np.column_stack((sources_batch, destinations_batch, r_batch))
            all_predictions = np.array(all_predictions)
            all_ground_truth = np.array(all_ground_truth)
            list_k = [x for x in range(1, 11)]
            for k in list_k:
                hr, ndcg = hr_ndcg(all_ground_truth, all_predictions, k)
                hr_ndcg_total_dict[str(k)][0] += hr
                hr_ndcg_total_dict[str(k)][1] += ndcg

        for key in hr_ndcg_total_dict:
            hr_ndcg_ave_dict[key] = [hr_ndcg_total_dict[key][0] / num_test_batch,
                                     hr_ndcg_total_dict[key][1] / num_test_batch]
        hr5 = hr_ndcg_ave_dict['5'][0]
        hr8 = hr_ndcg_ave_dict['8'][0]
        hr10 = hr_ndcg_ave_dict['10'][0]
        ndcg5 = hr_ndcg_ave_dict['5'][1]
        ndcg8 = hr_ndcg_ave_dict['8'][1]
        ndcg10 = hr_ndcg_ave_dict['10'][1]

        return hr5,hr8,hr10, ndcg5,ndcg8,ndcg10

def hit_rate(predicted_ranking, true_items,k):
    """
    Calculate the Hit Rate (HR) metric.

    Parameters:
    - predicted_ranking: List of items ranked by the model's predicted scores (in descending order)
    - true_items: Set of items that the user actually likes

    Returns:
    - hr: Hit Rate
    """
    if k is not None:
        predicted_ranking = predicted_ranking[:k]
    hits = 0
    for item in predicted_ranking:
        if item in true_items:
            hits += 1
    hr = hits / len(true_items) if len(true_items) > 0 else 0
    return hr


def ndcg(predicted_ranking, true_items, k=None):
    """
    Calculate the Normalized Discounted Cumulative Gain (NDCG) metric.

    Parameters:
    - predicted_ranking: List or array of items ranked by the model's predicted scores (in descending order)
    - true_items: Set or list of items that the user actually likes
    - k: int, the number of top items to consider, default is None (consider all items)

    Returns:
    - ndcg_score: float, the NDCG score
    """
    if k is not None:
        predicted_ranking = predicted_ranking[:k]

    dcg = 0
    for i, item in enumerate(predicted_ranking):
        if item in true_items:
            dcg += 1 / np.log2(i + 2)
    idcg = 0
    true_ranking = np.zeros_like(predicted_ranking, dtype=int)
    for i, item in enumerate(predicted_ranking):
        true_ranking[i] = 1 if item in true_items else 0

    sorted_true_ranking = np.sort(true_ranking)[::-1]
    for i, score in enumerate(sorted_true_ranking):
        if score == 1:
            idcg += 1 / np.log2(i + 2)

    ndcg_score = dcg / idcg if idcg > 0 else 0
    return ndcg_score



def eval_node_classification(tgn, decoder, data, edge_idxs, batch_size, n_neighbors):
  pred_prob = np.zeros(len(data.sources))
  num_instance = len(data.sources)
  num_batch = math.ceil(num_instance / batch_size)

  with torch.no_grad():
    decoder.eval()
    tgn.eval()
    for k in range(num_batch):
      s_idx = k * batch_size
      e_idx = min(num_instance, s_idx + batch_size)

      sources_batch = data.sources[s_idx: e_idx]
      destinations_batch = data.destinations[s_idx: e_idx]
      timestamps_batch = data.timestamps[s_idx:e_idx]
      edge_idxs_batch = edge_idxs[s_idx: e_idx]

      source_embedding, destination_embedding, _ = tgn.compute_temporal_embeddings(sources_batch,
                                                                                   destinations_batch,
                                                                                   destinations_batch,
                                                                                   timestamps_batch,
                                                                                   edge_idxs_batch,
                                                                                   n_neighbors)
      pred_prob_batch = decoder(source_embedding).sigmoid()
      pred_prob[s_idx: e_idx] = pred_prob_batch.cpu().numpy()

  auc_roc = roc_auc_score(data.labels, pred_prob)
  return auc_roc
